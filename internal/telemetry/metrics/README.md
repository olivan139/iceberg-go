# Метрики libiceberg

Этот пакет экспортирует метрики через OTLP/HTTP и нацелен на агрегацию запросов к Hive, чтения Avro-манифестов, взаимодействия с HDFS, а также этапов планирования и фильтрации сканов. Ниже приведено описание встроенных инструментов и используемых атрибутов.

## Общие атрибуты

Каждый сигнал дополняется следующими ключами:

- `component` — подсистема (`hive`, `avro`, `hdfs`, `scan`, `scan_plan`).
- `operation` — конкретное действие внутри подсистемы (например, тип RPC или файловой операции). Присутствует не у всех метрик.
- `status` — результат выполнения (`ok` или `error`).

Дополнительные атрибуты могут передаваться вызывающей стороной для детализации (например, имя таблицы, путь файла, идентификатор снимка).

## Гистограммы (Float64Histogram)

| Имя | Назначение | Единицы |
| --- | --- | --- |
| `libiceberg.hive.request.duration_ms` | Время выполнения RPC в Hive Metastore. Используется для оценки латентности RPC по операциям. | миллисекунды |
| `libiceberg.avro.metadata.fetch.duration_ms` | Время открытия и чтения Avro-манифестов. Помогает обнаруживать «узкие места» в получении метаданных. | миллисекунды |
| `libiceberg.hdfs.request.duration_ms` | Продолжительность операций обращения к HDFS (открытие файла, чтение блоков и т. д.). | миллисекунды |
| `libiceberg.scan.filter.duration_ms` | Длительность применения фильтров (predicate pushdown, отбор манифестов). | миллисекунды |
| `libiceberg.scan.plan.transfer.duration_ms` | Время сериализации и передачи плана сканирования потребителю. | миллисекунды |
| `libiceberg.scan.plan.transfer.bytes` | Размер сериализованного плана сканирования (записывается как гистограмма для удобного анализа распределения). | байты |

## Счётчики (Int64Counter)

| Имя | Назначение | Единицы |
| --- | --- | --- |
| `libiceberg.hdfs.bytes` | Совокупный объём данных, прочитанных из HDFS. Значения накапливаются по каждой комбинации атрибутов. | байты |
| `libiceberg.scan.filtered.bytes` | Объём данных, оставшийся после фильтрации. Позволяет сравнивать исходный трафик HDFS и итоговый набор данных. | байты |

## Пользовательские метрики

Функции `CounterAdd` и `HistogramRecord` позволяют регистрировать дополнительные показатели по произвольным именам. Инструменты создаются лениво и переиспользуются между вызовами. Передаваемые атрибуты будут привязаны к новой временной серии в Prometheus.

## Ресурсы OTEL

При инициализации устанавливаются атрибуты ресурса:

- `service.name` — имя сервиса (по умолчанию `libiceberg`).
- `service.version` — версия сервиса (опционально).
- `service.instance.id` — уникальный идентификатор процесса (генерируется из имени хоста, PID и UUID).

Идентификаторы обеспечивают корректную агрегацию метрик при работе нескольких процессов одновременно.

## Правила эксплуатации

1. Вызывайте `Init` один раз в процессе и передавайте адрес OTLP-эндпоинта (например, OTEL Collector, настроенный на экспорт в Prometheus).
2. Перед завершением процесса вызывайте `Shutdown`, чтобы гарантировать отправку накопленных выборок.
3. Для потокового чтения из HDFS используйте обёртки пакета, чтобы счётчик байтов автоматически отражал реальный объём IO.
4. Размещайте дополнительные атрибуты (имя таблицы, тип запроса и т. п.) для лучшей диагностики в Grafana.

